{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8YXs4OdTWsR"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuBRbMnRYSV2"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations==0.4.6 -q\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install neptune-client -q\n",
        "import neptune.new as neptune\n",
        "from neptune.new.types import File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-eKt77WYhYF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoF6191Y4Sn4"
      },
      "outputs": [],
      "source": [
        "#cd to Dataset dir, structure as in readme\n",
        "%cd drive/MyDrive/Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NEPTUNE_PROJ_NAME = \"username/exampleprojname\"\n",
        "API_TOKEN = \"abc123==\"\n",
        "\n",
        "run = neptune.init(\n",
        "    project=NEPTUNE_PROJ_NAME,\n",
        "    api_token=API_TOKEN,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL02VwBNaLER"
      },
      "outputs": [],
      "source": [
        "#try out different augmentations here, list of options at https://github.com/albumentations-team/albumentations\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(64,64),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n",
        "        A.MultiplicativeNoise(multiplier=[0.5,2], per_channel=True, p=0.2),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(64,64),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n",
        "        A.MultiplicativeNoise(multiplier=[0.5,2], per_channel=True, p=0.2),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(64,64),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnCiMxEB-43x"
      },
      "outputs": [],
      "source": [
        "#change this to the number of classes in your dataset\n",
        "\n",
        "NUM_OF_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLVr2zRN4j0p"
      },
      "outputs": [],
      "source": [
        "train_data_path = 'train'\n",
        "valid_data_path = 'valid'\n",
        "test_data_path = 'test'\n",
        "classes = os.listdir('train')\n",
        "\n",
        "train_image_paths = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"train\")) for f in fn]\n",
        "valid_image_paths = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"valid\")) for f in fn]\n",
        "random.shuffle(train_image_paths)\n",
        "random.shuffle(valid_image_paths)\n",
        "test_image_paths = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"test\")) for f in fn]\n",
        "\n",
        "print('train_image_path example: ', train_image_paths[0])\n",
        "print('test_image_path example: ', test_image_paths[0])\n",
        "print('class example: ', classes[0])\n",
        "print(\"Train size: {}\\nValid size: {}\\nTest size: {}\".format(len(train_image_paths), len(valid_image_paths), len(test_image_paths)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HhLmEwz5BjE"
      },
      "outputs": [],
      "source": [
        "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
        "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
        "\n",
        "print(f'Class to index mapping: {class_to_idx}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgIVn45O5IHN"
      },
      "outputs": [],
      "source": [
        "#your custom dataset class def\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, image_paths, transform=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.image_paths[idx]\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        label = image_filepath.split(\"/\")[-2]\n",
        "        label = class_to_idx[label]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)['image']\n",
        "            \n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv1uyXna5Tq_"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_image_paths,train_transforms)\n",
        "valid_dataset = CustomDataset(valid_image_paths,train_transforms)\n",
        "test_dataset = CustomDataset(test_image_paths,test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYfTYbBO5WYJ"
      },
      "outputs": [],
      "source": [
        "print('The shape of tensor for 50th image in train dataset: ',train_dataset[49][0].shape)\n",
        "print('The label for 50th image in train dataset: ',train_dataset[49][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zfV4OhJ5lfo"
      },
      "outputs": [],
      "source": [
        "def visualize_augmentations(dataset, idx=0, samples=10, cols=5, random_img=False):\n",
        "    \n",
        "    dataset = copy.deepcopy(dataset)\n",
        "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
        "    rows = samples // cols\n",
        "    \n",
        "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12,8))\n",
        "    for i in range(samples):\n",
        "        if random_img:\n",
        "            idx = np.random.randint(1,len(train_image_paths))\n",
        "        image, lab = dataset[idx]\n",
        "        ax.ravel()[i].imshow(image)\n",
        "        ax.ravel()[i].set_axis_off()\n",
        "        ax.ravel()[i].set_title(idx_to_class[lab])\n",
        "        \n",
        "    plt.tight_layout(pad=1)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTFur3Wm5m5Z"
      },
      "outputs": [],
      "source": [
        "visualize_augmentations(train_dataset, np.random.randint(1, len(train_image_paths)), random_img=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGrpfo5N5oFd"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbL3RpxC5zms"
      },
      "outputs": [],
      "source": [
        "image_datasets = {'train': train_dataset, 'valid': valid_dataset, 'test': test_dataset}\n",
        "dataloaders = {'train': train_loader, 'valid': valid_loader, 'test': test_loader}\n",
        "dataset_sizes = {'train': len(train_dataset), 'valid': len(valid_dataset), 'test': len(test_dataset)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ_h-x926B_f"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=12):\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train() \n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            #log training and val data on neptune\n",
        "            if phase == 'train':\n",
        "              run[\"training/batch/loss\"].log(epoch_loss)\n",
        "              run[\"training/batch/acc\"].log(epoch_acc)\n",
        "\n",
        "            else:\n",
        "              run[\"valid/batch/loss\"].log(epoch_loss)\n",
        "              run[\"valid/batch/acc\"].log(epoch_acc)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLMF0bWn6GUN"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['valid']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {classes[preds[j]]}')\n",
        "                plt.imshow(inputs.cpu().data[j].swapaxes(0, 1).swapaxes(1,2))\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#change training parameters here if needed\n",
        "parameters = {\n",
        "    \"lr\": 0.001,\n",
        "    \"batch_size\": 16,\n",
        "    \"input_size\": 3 * 256 * 256,\n",
        "    \"n_classes\": NUM_OF_CLASSES,\n",
        "    \"momentum\": 0.9,\n",
        "    \"model_filename\": \"basemodel\",\n",
        "    \"device\": device,\n",
        "}\n",
        "\n",
        "#load a pretrained model, replace with a new final layer\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, NUM_OF_CLASSES)\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=parameters[\"lr\"], momentum=parameters[\"momentum\"])\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "#log all parameters on neptune\n",
        "run[\"config/hyperparameters\"] = parameters\n",
        "run[\"config/model\"] = type(model_ft).__name__\n",
        "run[\"config/criterion\"] = type(criterion).__name__\n",
        "run[\"config/optimizer\"] = type(optimizer_ft).__name__\n",
        "run[\"config/dataset/path\"] = \".\"\n",
        "run[\"config/dataset/transforms\"] = train_transforms\n",
        "run[\"config/dataset/size\"] = len(train_image_paths) + len(valid_image_paths) + len(test_image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjPTjqLX6bxG"
      },
      "outputs": [],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZtEaf9K_u-s"
      },
      "outputs": [],
      "source": [
        "fname = parameters[\"model_filename\"]\n",
        "torch.save(model_ft.state_dict(), f\"./{fname}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#log model architecture to neptune\n",
        "fname = parameters[\"model_filename\"]\n",
        "\n",
        "with open(f\"./{fname}_arch.txt\", \"w\") as f:\n",
        "    f.write(str(model_ft))\n",
        "\n",
        "run[f\"io_files/artifacts/{parameters['model_filename']}_arch\"].upload(\n",
        "    f\"./{parameters['model_filename']}_arch.txt\"\n",
        ")\n",
        "run[f\"io_files/artifacts/{parameters['model_filename']}\"].upload(\n",
        "    f\"./{parameters['model_filename']}.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#visualize preds on neptune\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "model_ft.eval()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model_ft.to(\"cpu\")\n",
        "\n",
        "n_samples = 50\n",
        "img = images[:n_samples]\n",
        "probs = F.softmax(model_ft(img), dim=1)\n",
        "probs = probs.data.numpy()\n",
        "\n",
        "for i, ps in enumerate(probs):\n",
        "    pred = classes[np.argmax(ps)]\n",
        "    gt = classes[labels[i]]\n",
        "    description = \"\\n\".join(\n",
        "        [\n",
        "            \"class {}: {}%\".format(classes[n], round(p * 100, 2))\n",
        "            for n, p in enumerate(ps)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    run[\"images/predictions\"].log(\n",
        "        File.as_image(img[i].squeeze().permute(2, 1, 0).clip(0, 1)),\n",
        "        name=f\"{i}_{pred}_{gt}\",\n",
        "        description=description,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#IMPORTANT: stop the neptune runtime after logging is completed\n",
        "\n",
        "run.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A1r4v_7P9Ak"
      },
      "outputs": [],
      "source": [
        "#loading the saved model for inference\n",
        "\n",
        "model_loaded = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_loaded.fc.in_features\n",
        "model_loaded.fc = nn.Linear(num_ftrs, NUM_OF_CLASSES)\n",
        "model_loaded.load_state_dict(torch.load(f\"./{fname}.pth\", map_location='cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2bs7D2A_8ng"
      },
      "outputs": [],
      "source": [
        "visualize_model(model_loaded)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Torch Image Classification Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
