{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e53787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import models\n",
    "\n",
    "import dataset\n",
    "import reasons\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b98181",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = \"Dataset/test\"\n",
    "PATH_TO_MODEL = 'basemodel.pth'\n",
    "NUM_OF_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85030a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mislabel():\n",
    "    \n",
    "    \"\"\"\n",
    "    Randomly mislabels 10% of each class with another label\n",
    "    Renames the mislabeled images by appending \"mislabeled\" to the front of the name\n",
    "    Returns a list of mislabeled images\n",
    "    \"\"\"\n",
    "    \n",
    "    all_classes = os.listdir('.')\n",
    "    mislabels = []\n",
    "    \n",
    "    for label in all_classes:\n",
    "        original_images = os.listdir(f'{label}')\n",
    "        num_of_samples = len(original_images)\n",
    "        to_mislabel = int(0.1*num_of_samples)  \n",
    "        classes = os.listdir('.')\n",
    "        classes.remove(label)\n",
    "        random.shuffle(classes)\n",
    "        \n",
    "        for i in range(to_mislabel):\n",
    "            old_name = f'{label}/{original_images[i]}'\n",
    "            new_label = random.sample(classes,1)[0]\n",
    "            new_name = f'{new_label}/~mislabeled_{original_images[i]}'\n",
    "            os.rename(old_name, new_name)\n",
    "            mislabels.append(new_name)\n",
    "            \n",
    "    return mislabels\n",
    "\n",
    "mislabels = mislabel()\n",
    "total_mislabeled = len(mislabels)\n",
    "\n",
    "model_loaded = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_loaded.fc.in_features\n",
    "model_loaded.fc = nn.Linear(num_ftrs, NUM_OF_CLASSES)\n",
    "model_loaded.load_state_dict(torch.load(PATH_TO_MODEL, map_location='cpu'))\n",
    "\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da978cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of mislabels: {total_mislabeled}\")\n",
    "print(f\"Mislabeled images: {mislabels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKE SURE CLASSES ARE IN THE SAME ORDER AS IN COLAB, if not, copy paste class list from colab/match the class indices here to the same ones that the model was trained on\n",
    "classes = os.listdir('.')\n",
    "\n",
    "test_image_paths = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser('.')) for f in fn]\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(64,64),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "total_annos = len(test_image_paths)\n",
    "test_dataset = dataset.CustomDataset(test_image_paths,classes,test_transforms)\n",
    "doubt = reasons.TorchDoubtLab(model_loaded, test_dataset)\n",
    "\n",
    "def get_metrics(flagged, total_mislabels, total_annos):\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for flagged_img in flagged:\n",
    "        if 'mislabeled' in flagged_img:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    fn = total_mislabels - tp\n",
    "    print(total_mislabels, tp)\n",
    "    tn = total_annos - (tp+fp+fn)\n",
    "    \n",
    "    metrics['accuracy'] = f\"{100*(tp+tn)/total_annos}%\"\n",
    "    metrics['fp'] = fp\n",
    "    metrics['fn'] = fn\n",
    "    metrics['tp'] = tp\n",
    "    try:\n",
    "        precision = tp/(tp+fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "    metrics['precision'] = precision\n",
    "    recall = tp/(tp+fn)\n",
    "    try:\n",
    "        recall = tp/(tp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "    metrics['recall'] = recall\n",
    "    try:\n",
    "        metrics['f1'] = (2*precision*recall)/(precision+recall)\n",
    "    except ZeroDivisionError:\n",
    "        metrics['f1'] = 0\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092df44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_conf_indices = doubt.ProbaReason()\n",
    "x = doubt.get_flagged_images(low_conf_indices)\n",
    "get_metrics(x, total_mislabeled, total_annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_pred_indices = doubt.WrongPrediction()\n",
    "x = doubt.get_flagged_images(wrong_pred_indices)\n",
    "get_metrics(x, total_mislabeled, total_annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb245d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_conf_indices = doubt.ShortConfidence()\n",
    "x = doubt.get_flagged_images(short_conf_indices)\n",
    "get_metrics(x, total_mislabeled, total_annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89863b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_conf_indices = doubt.LongConfidence()\n",
    "x = doubt.get_flagged_images(long_conf_indices)\n",
    "get_metrics(x, total_mislabeled, total_annos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doubtlab",
   "language": "python",
   "name": "doubtlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
